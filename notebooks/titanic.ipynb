{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c30bb3d453557629",
   "metadata": {},
   "source": [
    "# Business Understanding\n",
    "## 1 Determining Business Objectives\n",
    "### Finding Business Objectives\n",
    "In this project, the Titanic passenger dataset is used to analyze which characteristics most influenced survival during the sinking. The dataset includes passenger attributes that are used to build a machine learning model to predict whether a passenger would survive.\n",
    "\n",
    "Objectives:\n",
    "Build a machine learning model to accurately predict who survived the Titanic disaster.\n",
    "Tip:\n",
    "Identifying meaningful patterns in features will help improve model’s accuracy\n",
    "\n",
    "\n",
    "### 1.1 Business Background\n",
    "#### Determine Organizational Structure\n",
    "This project is done by me. I am responsible for all project activities, including data preparation, analysis, modeling, evaluation, and documentation. \n",
    "The primary stakeholders and benefiting units include \n",
    "* (1) the academic program and instructor, who use the project to assess practical data science and CRISP-DM skills\n",
    "* (2) future students and data science learners, who can use the project as a reference example of predictive modeling and structured data mining workflow.\n",
    "\n",
    "#### Describe Problem Area\n",
    "The problem was that there was noe enough lifeboats on Titanic resulting in the death of 1502 out of 2224 people. \n",
    "The motivation behind this project is to apply CRISP-DM and build a model that predicts Titanic survival from passenger data.\n",
    "\n",
    "#### Describe Current Solution\n",
    "Currently, there is no existing solution.\n",
    "\n",
    "\n",
    "### 1.2 Defining Business Objectives\n",
    "The objective of this project is to use data mining techniques to analyze historical passenger data from the Titanic disaster and build a predictive model that estimates the probability of passenger survival. Given a set of passenger attributes such as class, age, sex, family relationships, and fare, the problem is to identify patterns and relationships that influenced survival outcomes and to use these patterns to predict whether a passenger would have survived. \n",
    "\n",
    "Business questions (precisely defined)\n",
    "* Which passenger characteristics like sex, class, age, fare, family relationships have the strongest influence on survival?\n",
    "* Can a predictive model accurately classify whether a passenger survived based on available features?\n",
    "* Which variables contribute most to the model’s predictions?\n",
    "* How well do different classification models perform on this problem?\n",
    "\n",
    "Other business (project) requirements\n",
    "* The project must follow the CRISP-DM methodology and be structured accordingly\n",
    "* All steps must be clearly documented and justified\n",
    "* The workflow must be reproducible\n",
    "* Proper model validation and evaluation metrics must be used\n",
    "* Visualizations and tables must support analytical conclusions\n",
    "* Results must be consistent with the stated objective and supported by data\n",
    "\n",
    "### 1.3 Business Success Criteria\n",
    "* Predictive performance: The final model achieves at least 0.75 accuracy on a held-out test set .\n",
    "* Transparent reporting: Results are reported with a confusion matrix and key metrics (accuracy, precision, recall, F1, ROC-AUC) so false positives/false negatives are visible.\n",
    "* Explainability: The project identifies and explains the main survival drivers using feature importance / coefficients plus supporting plots or tables.\n",
    "* Reproducibility: The full workflow runs end-to-end in a single notebook with fixed random seeds, documented assumptions, and all steps needed to reproduce results.\n",
    "\n",
    "Subjective quality criteria\n",
    "* Clarity: Conclusions are clearly stated and directly supported by the reported metrics and visualizations.\n",
    "* Process quality: The notebook follows CRISP-DM phases with clear documentation of decisions (data cleaning, feature engineering, model choice, evaluation).\n",
    "\n",
    "## 2 Assessing the Situation\n",
    "Data\n",
    "The data available for this project is a single structured dataset in CSV format named titanic1.csv. Each row represents one passenger. The dataset is labeled, which makes it suitable for supervised machine learning, especially a binary classification task survived vs. not survived.\n",
    "\n",
    "The dataset contains the following main columns:\n",
    "* Passengerid: unique passenger ID\n",
    "* Age: passenger age number\n",
    "* Fare: ticket price number\n",
    "* Sex: encoded as 0 or 1\n",
    "* sibsp: number of siblings/spouses aboard\n",
    "* Parch: number of parents/children aboard\n",
    "* Pclass: passenger class (1, 2, 3)\n",
    "* Embarked: encoded embarkation port\n",
    "* 2urvived: target variable 0 or 1\n",
    "* zero / zero.*: columns filled with 0 values\n",
    "\n",
    "Some variables are already encoded  Sex, Embarked, so their meaning needs to be verified during Data Understanding. The dataset also includes multiple “zero” columns, which will be checked and removed during Data Preparation if they contain no useful information\n",
    "\n",
    "The project is carried out by one student. Basic Python and machine learning knowledge is assumed from the course, and guidance is available through course materials and the instructor.\n",
    "\n",
    "Risks   \n",
    "The main risks are missing or inconsistent which will need to be verified, non-informative columns like the zero columns, and overfitting due to the dataset size. There is also a risk of misunderstanding encoded variables if there is no clear explain behind it \n",
    "\n",
    "Contingency plan\n",
    "To handle these risks, the dataset will be checked for missing values and consistency, non-informative columns will be removed after verification.\n",
    "\n",
    "### 2.1 Resource Inventory\n",
    "This project is executed on a personal computer. Its basic machine learning, no specific one needed. The primary data source is a single CSV file (titanic1.csv) provided as part of the course assignment. The dataset is stored locally and loaded directly in the Jupyter Notebook using Python. All data preparation, modeling, evaluation, and documentation are performed within the same Jupyter Notebook.\n",
    "\n",
    "\n",
    "### 2.2 Requirements, Assumptions, and Constraints\n",
    "\n",
    "#### Determine Requirements\n",
    "* The project must follow the CRISP-DM methodology and be structured accordingly\n",
    "* All steps must be clearly documented and justified\n",
    "* The workflow must be reproducible\n",
    "* Proper model validation and evaluation metrics must be used\n",
    "* Visualizations and tables must support analytical conclusions\n",
    "* Results must be consistent with the stated objective and supported by data\n",
    "\n",
    "#### Clarify Assumptions\n",
    "\n",
    "Data assumption\n",
    "* The survival label is correct\n",
    "* 2urvived correctly indicates whether the passenger survived (0/1)\n",
    "* The columns represent what they claim\n",
    "* Age is age in years, Fare is ticket price, Pclass is class\n",
    "* Missing values are not completely random, but are manageable\n",
    "* The available features are sufficient for the classification task\n",
    " \n",
    "The “zero” columns are non-informative placeholders\n",
    "I assume columns full of zeros do not contain useful signal and can be removed after verification.\n",
    "\n",
    "I assume the dataset is mostly correct and complete enough to perform analysis. I also assume the survival label is reliable, and that missing values and non-informative columns can be handled during data preparation.\n",
    "\n",
    "#### Constraints\n",
    "* Deep learning techniques are not permitted.\n",
    "* The project must be completed in a single Jupyter Notebook\n",
    "* Deployment\n",
    "\n",
    "### 2.3 Risks and Contingencies\n",
    "* Scheduling: The projects take 5 weeks.At the end of the week 5 it is necessary to submit the related documents mentioned before.\n",
    "* Financial: No financial risks\n",
    "* Data: The data should not be poor quality. It was made for educational purpose by the professors. \n",
    "* Results: ______\n",
    "\n",
    "### 2.4 Terminology\n",
    "Survived (2urvived)- Binary target variable indicating whether a passenger survived 1 or did not survive 0.\n",
    "\n",
    "Binary classification - A machine learning task where the outcome has two possible values 1 or 2.\n",
    "\n",
    "Missing values - Data entries that are not present in the dataset and must be handled during data preparation.\n",
    "\n",
    "Encoding - The process of converting categorical variables into numerical form, so they can be used by machine learning models.\n",
    "\n",
    "CRISP-DM - A standard data mining methodology used to structure the project from business understanding to evaluation.\n",
    "\n",
    "### 2.5 Cost/Benefit Analysis\n",
    "There are no costs. The benefit of better data understanding is to have better knowledge of statics if a ship crashes and who will survive.\n",
    "\n",
    "## 3 Determining Data Mining Goals\n",
    "\n",
    "### Data Mining Goals\n",
    "The task is a supervised classification problem, where the goal is to predict a binary outcome: whether a passenger survived or did not survive the Titanic disaster.\n",
    "\n",
    "Technical goals/Data Mining goals:\n",
    "* Build at least one machine learning classification model that predicts survival based on passenger attributes\n",
    "* Achieve a minimum accuracy of approximately 75% on the test set, while also reporting complementary metrics\n",
    "\n",
    "### Data Mining Success Criteria\n",
    "Model performance is evaluated using a train/test split. The trained model performance is measured primarily using accuracy, supported by a confusion matrix to analyze classification errors.\n",
    "\n",
    "Quantitative success benchmarks:\n",
    "* The data mining task is considered successful if the model achieves approximately 75% or higher accuracy on the test set while maintaining balanced performance across classes.\n",
    "\n",
    "Subjective success criteria:\n",
    "* Results and evaluation metrics are clearly explained and easy to interpret\n",
    "* The modeling decisions and outcomes are logically consistent with the project objective\n",
    "* Key survival factors are interpretable and supported by data analysis and visualizations\n",
    "\n",
    "## 4 Project Plan\n",
    "### 4.1 Project Plan\n",
    "#### Week 1 — Business Understanding\n",
    "- Define the project objective: predict Titanic passenger survival using historical data.\n",
    "- Formulate business questions and data mining questions.\n",
    "- Define data mining goals and success criteria (e.g., target accuracy, evaluation metrics).\n",
    "- Identify requirements, assumptions, and constraints.\n",
    "- Document the planned CRISP-DM structure of the notebook.\n",
    "\n",
    "#### Week 2 — Data Understanding\n",
    "- Load the provided `titanic1.csv` dataset in the Jupyter Notebook.\n",
    "- Describe the dataset structure, features, and target variable.\n",
    "- Perform exploratory data analysis (EDA) using summary statistics and visualizations.\n",
    "- Identify data quality issues (missing values, class imbalance, outliers).\n",
    "- Decide which features are relevant for modeling.\n",
    "\n",
    "#### Week 3 — Data Preparation\n",
    "- Clean the data by handling missing values and inconsistencies.\n",
    "- Encode categorical variables and scale numerical features if required.\n",
    "- Engineer additional features where appropriate.\n",
    "- Split the data into training and test sets.\n",
    "- Ensure preprocessing steps are reproducible and clearly documented.\n",
    "\n",
    "#### Week 4 — Modeling\n",
    "- Train a baseline classification model using a standard ML library.\n",
    "- Train and compare additional classical machine learning models.\n",
    "- Tune key hyperparameters where necessary.\n",
    "- Explain how the selected model(s) work and justify the final choice.\n",
    "\n",
    "#### Week 5 — Evaluation\n",
    "- Evaluate the final model on the test set.\n",
    "- Report accuracy and a confusion matrix (and other relevant metrics).\n",
    "- Analyze model errors and limitations.\n",
    "- Assess whether the data mining success criteria are met.\n",
    "- Summarize findings and conclusions.\n",
    "\n",
    "\n",
    "### 4.2 Assessing Tools and Techniques\n",
    "Based on the structured, tabular nature of the data and the binary target variable, classical supervised classification techniques such as Logistic Regression, Decision Tree–based models, and ensemble methods are expected to produce the best results.\n",
    "\n",
    "- **Tools:**  \n",
    "  The project is implemented in **Python using a Jupyter Notebook**. Core libraries include `pandas` and `numpy` for data handling, `matplotlib`/`seaborn` for visualization, and `scikit-learn` for modeling and evaluation.\n",
    "\n",
    "- **Selected techniques:**  \n",
    "  Since the objective is to predict passenger survival, the task is treated as a **supervised classification** problem. Classical machine learning algorithms are considered, including:\n",
    "  - Logistic Regression (baseline and interpretable model)\n",
    "  - Decision Tree–based models (to capture non-linear relationships)\n",
    "  - Ensemble methods such as Random Forest or Gradient Boosting (for improved performance)\n",
    "\n",
    "- **Rationale for technique selection:**  \n",
    "  These techniques are well-suited for structured tabular data, support binary classification, and are allowed under the project constraints (no deep learning). They also provide mechanisms for model evaluation and interpretability.\n",
    "\n",
    "- **Evaluation support:**  \n",
    "  `scikit-learn` provides built-in tools for **train/test splitting**, **cross-validation**, and **performance metrics** (accuracy, confusion matrix, precision, recall), enabling transparent and reproducible assessment of model performance.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
